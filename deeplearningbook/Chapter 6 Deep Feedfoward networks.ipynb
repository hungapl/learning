{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer perceptron (MLP)\n",
    "\n",
    "The MLP is a class of neural network that consists of three or more layers (an input and an output layer with one or more hidden layers) of nonlinearly-activating nodes. Since MLPs are fully connected, each node in one layer connects with a certain weight ${\\displaystyle w_{ij}} w_{ij}$ to every node in the following layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedfoward network\n",
    "\n",
    "A feedforward network defines a mapping y = f(x;$\\theta$) and learns the parameters of $\\theta$ that result in the best function approximation.  \n",
    "\n",
    "These functions are called **feedfoward** because information flows through the function being evaluated from **x** \n",
    "\n",
    "When feedforward neural networks are extended to include feedback connections, they are called **recurrent neural networks**\n",
    "\n",
    "Feedforward neural networks are called **networks** because they are typically represented by composing together many different functions.  The model is associated with a directed acyclic graph describing how the functions are composed together.  For example, we might have three functions f1, f2 and f3 connected in a chain, to form f(x) = f3(f2(f1(x))).  In this case, f1 is called the first layer of the network, f2 is called the second layer, and so on.  The overall length of the chain gives the **depth** of the model.  The final layer of the feedforward network is called the **output layer**. \n",
    "\n",
    "During neural network training, we drive f(x) to matching f**(x).  The training data provides us with noisy, approximate examples of f**(x) evaluated at different training points.  Each example x is accompanied by a label y.  The training examples specify directly what the output layer must do at each point x; it must produce a value that is close to y. \n",
    "\n",
    "Because the training data does not show the desired output of each layers, these layers are called **hidden layers**.\n",
    "\n",
    "The dimensionality of these hidden layers detremines the **width** of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models has the obvious defect that the model capacity is limited to linear functions.\n",
    "To extend linear models to represent nonlinear functions of x, we can apply the linear model to a transformed input $\\phi$(x) where $\\phi$ is a nonlinear transformation\n",
    "The strategy of deep learning is to learn $\\phi$.  In this approach, we have a model y = f(x;$\\theta, \\omega) = \\phi$ (x;$\\theta$)^T $\\omega$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each layer of the neural network is a vector-valued representation and each element of the vector can be considered as a **unit** (or neuron).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example neural network for solving XOR operation\n",
    "- A feedforward neural network with one hidden layer and two hidden units\n",
    "The hidden units **h** is computed by a function f^1(x, W, c) where W are the weights and c are the biases.  The values of these hidden units are then used as the input for a second layer.\n",
    "\n",
    "Most neural networks use an **aﬃne transformation** controlled by learned parameters,\n",
    "followed by a ﬁxed nonlinear function called an activation function.\n",
    "\n",
    "The **activation function** is typically chosen to be a functio that is applied element-wise.  In modern neural networks, the default recommdendations is to use the rectified linear unit or **ReLU**.  This unit is defined by a function is a very close to linear.  Because ReLU are nearly linear, they preserve many of the properties that make linear models easy to potimize with gradient-based methods.  They also preserve many of the properties that make linear models generalize well.  \n",
    "\n",
    "*TODO* Try solve XOR by hand Chpt 6 Page 171"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-linearity of a neural network causes most loss functions to become nonconvex -- there can be multiple local minima, nonconvex loss functions cannot guarantee global convergence and is sensitive to the values of the initial parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Batch) gradient descent versus stochastic gradient descent\n",
    "In some cases, evaluating the sum-gradient may require expensive evaluations of the gradients from all summand functions.  Hence, the stochastic gradient descent approach is adopted.  Instead of computing the true gradient, only the gradient at a single training sample is used.  Single pass involves:\n",
    "1. Randomly shuffled the training set\n",
    "2. For each sample in the trainng set: i=1, 2... N.  Updating the weights based on the gradient evaluated at training sample i. Repeat until an appropiate minimum is reached\n",
    "\n",
    "Usually a single pass is not sufficient, if so proceed to second pass of the training set by shuffling the training set again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO* Revisit 6.2.1.1 and 6.2.1.2\n",
    "\n",
    "## Output units\n",
    "\n",
    "The choice of cost function is tightly coupled with the choice of output unit. Mostof the time, we simply use the cross-entropy between the data distribution and themodel distribution. The choice of how to represent the output then determinesthe form of the cross-entropy function\n",
    "\n",
    "### Linear Units for Gaussian Output Distributions\n",
    "One simple kind of output unit is based on an aﬃne transformation with no nonlinearity.  Linear output layers are often used to produce the mean of a conditional Gaussian distribution.  Maximizing the log-likelihood is then equivalent to minimizing the **mean squared error**. \n",
    "\n",
    "*Distribution of output value is assumed to follow a Gaussian distribution.??**\n",
    "\n",
    "### Sigmoid units for Bernoulli Output Distrubutions\n",
    "Many tasks require predicting the value of a binary variable *y*.  The maximum likelihood approach is to define a Bernoulli distribution.  Suppose we were to use a linear unit and threshold its value to obtain a valid probability.  The issue with thresholding is if anytime that wh + b strayed outside the unit interval, the gradient of the output of the model wrt its parameters would be 0.  This is problematic because the learninng alogirthm no longer has a guide for how to improve the correpsonding parameters.\n",
    "\n",
    "*TODO* Revisit 6.2.2.2\n",
    "\n",
    "Exponentiation following by normalization yields a valid probability distribution?? i.e. entire vector (y) sums to 1\n",
    "\n",
    "### Softmax units for Multinoulli Output Distributions\n",
    "Any time we wish to represent a probability distribution over a discrete variablewithnpossible values, we may use the softmax function. This can be seen as a generalization of the sigmoid function.  The softmax function is rarely use as activitation function  of a hidden unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing gradient problem\n",
    "\n",
    "Traditional activation function such as hyperbolic tangent function have gradients in the range (0, 1) and backprogagration computes gradient by the chain rule.  This has the effect of multiple n of these small numbers to compute gradients of the front layers in a n-layer network, meaning the gradient decreases exponentially with n causing the front layers train very slowly.  As the gradient become vanishly small, this stops the neural network from further training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "Layers need not be connected in a chain, even though this is the common practice.  \n",
    "\n",
    "Many architectures build a main chain then add extra architectural features to it, such as skip connections - from layer i to layer i + 2 or higher.  These skip connections make it easier for the gradient to flow from output layers to layers nearer to the input.  \n",
    "\n",
    "&darr; node connections &rArr; &darr;  # of parameters &rArr; &darr; computation \n",
    "\n",
    "> Experiment has shown that deeper network with reduced number of connections can yield higher accuracy than fully connected shallow numbers.  \n",
    "\n",
    "For example, convolution neural network uses sparse connections that are very effective for computer vision problems.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation\n",
    "\n",
    "In wikipedia, this term is referred as a method specifically for training neural network, it is a iterative method that follows the gradient descent approach to improve the network.\n",
    "\n",
    "While the book author argues that back-propagation is a numerical method for efficiently evaluating the gradient of a function by exploiting the chain rule.  During the training of a neural network, back-propagation is used for finding the derivative of the cost function wrt to the parameters, while gradient descent is the approach for changing the weights of the network.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
